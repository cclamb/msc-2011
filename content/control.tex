\section{Control Theoretic Model}\label{sec:control}
\label{data}

Modeling the behavior of the workload in a computing infrastructure is challenging given the difficulties to non-linear identification techniques, the model uncertainty
generated by the complexity of the system as well as the Multi-Input Multi-Output (MIMO) nature of the system. Several alternatives have been presented
to cover the main features of the workload in a computing infrastructure such as the fluid approximation model \cite{Malrait-2010}, or the approximation of the relation between
the resource allocation and a given performance measure \cite{Padala-2009},\cite{Nathuji-2010}.

Optimal control is a common approach to calculate the resource allocation according to the actual workflow and the power consumption of the system 
by minimizing a cost function. This minimization can be carried out by using partial derivatives \cite{Abdelzaher-SIGMETRICS-2008},\cite{Malrait-2010}, Linear Quadratic Control (LQC)
\cite{Fu-FeBID-2009},\cite{Padala-2009}, or by applying Model Predictive Control (MPC) \cite{Nathuji-2010},\cite{Wang-2010}. The optimization problem
consists of calculating a control input such that the cost of the control law is minimized while the required SLO of
a set of applications is partially or completely reached.

\subsection{Model Estimation and Optimal Control}\label{workopcontrol}
In previous works \cite{Abdelzaher-SIGMETRICS-2008},\cite{Padala-2009}, the implemented control technique is composed of an online 
model estimator and a Multi-Input Multi-Output resource allocation controller as shown in Fig. \ref{block}. The main goal of this controller is to optimally allocate the virtualized resources 
on a computing infrastructure so that the system can fulfill the required SLO. In current data center architectures, every tier of an application resides in a \emph{virtual machine} (VM) 
and a multi-tier application can run on several nodes. In this set up, several applications can be executed in one node, thus reducing the number 
of nodes in the computing infrastructure and minimizing costs.
\begin{figure}
\begin{center}
\begin{tabular}{c}
\scalebox{0.5}{\includegraphics{block_model}}
\end{tabular}
\end{center}
\caption{Block diagram of the Optimal Controller with Model Estimator.}
\label{block}
\end{figure}

The model estimator uses an Auto-Regressive (AR) model to approximate the relation between the resource allocation of the application
$a \in A$, namely $\mathbf{u}_{a}(k) = \{ \mathbf{u}_{a,r,t}:r \in R, t \in T_{a} \}$ and the peformance output $y_{a}(k)$ related to $a$. The AR model proposed in \cite{Abdelzaher-SIGMETRICS-2008} is given by,
\begin{eqnarray}
 y_{a}(k+1) &=& \sum_{l=1}^{n}a_{l}(k)y_{a}(k+1-l) \nonumber \\
& + & \sum_{m=0}^{n-1}\mathbf{b_{m}}^{T}(k)\mathbf{u}_{a}(k-m). \nonumber
\end{eqnarray}
We denote by $\mathbf{u}_{a,r,t}$ the actual allocation of the resource $r \in R$ for the application $a \in A$ in tier $t \in T_{a}$.
$A$ is the set of all hosted applications, $R$ is the set of all resource types considered and $T_{a}$ is the set of all tiers 
associated to application $a$. The scalar parameters $a_{l}(k)$ and the parameter vectors $\mathbf{b_{m}}(k)$ are estimated 
through a recursive least square (RLS) algorithm.
The optimizer searches for the required allocation vector ${\mathbf{\bar{u}}_{a}}$ that guarantees the performance target of the application $a$ while avoiding oscillations in 
resource allocation. This may be achieved by calculating $\mathbf{\bar{u}}_{a}$ that minimizes the following cost function,
\begin{equation}
 J_{a} = \left(y_{a}(k+1) - \bar{y}_{a}(k+1) \right)^{2} + q \| \mathbf{\bar{u}}_{a}(k) - {\mathbf{u}_{a}}(k-1) \|^{2}.
\label{cost01}
\end{equation}
where $\bar{y}_{a}(k)$ is the desired performance associated to the application $a$. Note that the function $J_a$ is minimized for $\left(y_{a}(k) - \bar{y}_{a}(k) \right)^{2} \approx 0$
 leading the application $a$ to approach the desired performance. Furthermore (\ref{cost01}) is minimized if the difference 
$\| {\mathbf{u^{*}}_{a}} - {\mathbf{u}_{a}}(k-1) \|$ becomes smaller \emph{i.e.} when large changes in the resource allocation  during a sample period are avoided.
By solving $\frac{\partial J_{a}}{\partial{\mathbf{u}(k)}} = 0$ for $\mathbf{u}_{a}(k)$ the optimal control law for resource allocation is given by,
\begin{eqnarray}
 {\mathbf{\bar{u}}_{a}^{*}}(k) & = & ({\mathbf{b}_{0}\mathbf{b}_{0}}^{T} + qI)^{-1}\left[ \left(\bar{y}_{a} - \sum_{l=1}^{n}a_{l}y_{a}(k-l+1)\right. \right. \nonumber \\
& & \left. \left.- \sum_{m=1}^{n-1}\mathbf{b}_{m}^{T}\mathbf{u}_{a}(k-m)\right) + q\mathbf{u}_{a}(k-1) \right], \nonumber
\end{eqnarray}
with $I$ the identity matrix and $q \in \Re$ a scaling factor. Note that, $a_i, b_j$ with $i=1,2,\cdots,n$, $j=0,1,2,\cdots,n-1$ are functions of $k$.


It might happen that the computing infrastructure cannot satisfy the resource allocation that has been calculated by the controller.
On that matter, Padala \emph{et. al.,} present in \cite{Padala-2009} a complementary layer in the workload control called \emph{NodeController}. This module takes the resource 
allocation calculated by the optimal control (called \emph{AppController} in \cite{Padala-2009}) and, if the total requested allocation is less than the available 
capacity of the system, it assigns the resources as the optimal controller dictates. On the other hand, 
when the total resource allocation is higher than the available capacity we have  \emph{contention}. In such cases,
a new optimization problem is carried out in order to minimize the error between the required application performance and the 
actual one.

Padala \emph{et. al.,} propose the following example in \cite{Padala-2009}. Two nodes namely, $n_{1}$ and $n_{2}$ hosting applications 1 and 2, sharing 
CPU and disk. Then, from application 1 we get the requests 
$\bar{u}_{1,cpu,web}$ and $\bar{u}_{1,disk,web}$.
Similarly, from application 2 we get the requests $\bar{u}_{2,cpu}$ and $\bar{u}_{2,disk}$.
Let us assume that node $n_{1}$ has enough capacity to fulfill the request for only one of the available resources. 
Modeling the shortage of resources we get $\Delta u_{1,r,web} = \bar{u}_{1,r,web}-u_{1,r,web}$ and 
$\Delta u_{2,r} = \bar{u}_{2,r}-u_{2,r}$. This problem is expressed in \cite{Padala-2009} as a constrained optimization problem,
\begin{eqnarray}
 \min J_{n1} & = & w_{1}\left(\frac{\partial y_{1}}{\partial u_{1,r,web}}\Delta u_{1,r,web} \right)^{2} \nonumber \\
 &&+
w_{2}\left(\frac{\partial y_{2}}{\partial u_{2,r}}\Delta u_{2,r} \right)^{2} \label{costn1} \\
\mbox{subject to} & & \nonumber \\
 \Delta u_{1,r,web} + \Delta u_{2,r} & \geq & \bar{u}_{1,r,web} + \bar{u}_{1,r,web} + \bar{u}_{2,r}-1 \nonumber \\
 \label{cond1} \\
\Delta u_{1,r,web} & \leq & 0, \label{cond2} \\
\Delta u_{2,r} & \leq & 0. \label{cond3}
\end{eqnarray}
where $\frac{\partial y_{1}}{\partial u_{1,r,web}}\Delta u_{1,r,web}$ estimates the error between the
requested and actual performance of application 1.
The condition in (\ref{cond1}) imposes a capacity constraint
that when violated means contention of one of the resources. The conditions given by (\ref{cond2}) and (\ref{cond3})
guarantee that no application can exceed its target performance to the detriment of the other.  
The weights $w_{1}$ and $w_{2}$ determine the priority of the applications and the lower the weight, the greater the degradation.

Getting back to our example of Nimbus Cloud Corporation, we can map the SLAs to our actual control problem. Notice that the input of the system in Fig. \ref{block}, corresponds to
the vector of required performance measurements for each application $a \in A$, then each entry of the vector is $\bar{y}_{a}(k)$. Let us assume that the outputs of the system
are \emph{uptime} $t_{u}$, \emph{latency} $\ell$ and \emph{abandon rate} $\alpha$, which are measurable. Latency is the time a server needs 
to process a request from the client. Abandon rate of a server is the ratio between the rejected requests and the total number of received requests. 
Nimbus Cloud Corporation is able to assign 
the SLO values per application we require as a client and put them in the input array $\bar{y}_{a}(k)$. Since the values are fixed thresholds of performance, the indicator functions of 
performance are straighforward, \emph{e.g.,} 

\begin{eqnarray}
&\left( \ell \geq 300 ms \land \ell^{-1} \geq \frac{1}{650ms} \right)& \nonumber \\
&\left(t_{u} \geq 95\%\right)& \nonumber \\
&\left(\alpha^{-1} \geq \frac{1}{10\%}\right)& \nonumber
\end{eqnarray}
Using the previous conditions the indicator functions will return \emph{true} if $300ms \leq \ell \leq 650ms$, similarly
 it will return \emph{true} if the minimum uptime is provided and the abandon rate is under the indicated threshold. Notice that other performance indexes can be used such that
CPU utilization, memory usage or even the number of active processors in the computing infrastructure. Then, the SLO and 
actually the Service Level Indicators (SLI) are easily mapped into the depicted theoretical controls approach.